{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math stuff\n",
    "import numpy as np\n",
    "# For handling dataset\n",
    "import pandas as pd\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# For plotting\n",
    "#import seaborn as sns\n",
    "#sns.set_style(\"white\")\n",
    "# For list the feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# For feature transformation\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# helping to remove outliers\n",
    "from scipy.stats import iqr\n",
    "# For undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# metrics\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data in order to do some analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset contains 31 features which each one is a numerical data. <br />\n",
    "The feature Class is a categorical data labeling if the transaction is legit or fraud. <br />\n",
    "One of the characteristics is the highly imbalance between legit and fraud transaction.\n",
    "\n",
    "So, let's plot and see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "sns.countplot(df.Class, palette=\"Set2\")\n",
    "plt.xticks([0,1], ['Legit', 'Fraud'])\n",
    "plt.title('Ratio between legit x fraudulent transactions')\n",
    "\n",
    "fig.savefig('imgs/fig2 ratio-legitxfraud.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's summarize the whole data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary is hard to see something. But, here some things to notice:\n",
    "* The mean of the feature V1 to V28 are next to zero.\n",
    "* The difference between the max value and the 75% quantile of the feature Amount is huge.\n",
    "\n",
    "\n",
    "Let's plot the distributions of the features Vs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = df.columns[1:-2]\n",
    "print feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 12))\n",
    "\n",
    "for idx, feat in enumerate(feats):\n",
    "    plt.subplot(7, 4, idx+1) \n",
    "    sns.distplot(df[feat])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('imgs/Vs distplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above is clear to see that the mean is around zero. So, it reflects the summary. <br />\n",
    "Another thing to notice is that by the extension of the x-axis, show us that all them have outliers. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.title('Distribution of the feature \"Amount\"')\n",
    "sns.distplot(df.Amount, bins=1000)\n",
    "plt.xlim(0, 1000)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('imgs/fig3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature amount is positively-skewed. So, it will need a transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "sns.distplot(df.Time)\n",
    "plt.title('Distribution of the feature \"Time\"')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('imgs/fig4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature presents somehow a bimodal distribution. Since, the dataset contains transactions of two days, this could be a reflection of it. <br /><br />\n",
    "Now that we had an overview about the dataset, it might be a good idea to choose the features that most explain the relation between legit and fraud.\n",
    "\n",
    "I'll be doing this through Random Forest and list the features by importance. <br />\n",
    "Since Decision Trees aren't sensitive to outliers, it should be fine to just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I won't be working with recurrent model, I'll be ignoring this feature\n",
    "del df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the data to work\n",
    "X = df.iloc[:,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(X.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separating the predictors and the labels\n",
    "X, y = X.iloc[:,:-1], X.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(ratio={0:492*20, 1:492}, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_candidates = [\n",
    "  {'n_estimators': [5, 10, 15, 20], 'criterion': ['gini', 'entropy'], \\\n",
    "   'random_state':[0], 'class_weight':['balanced', None], 'bootstrap':[True], \\\n",
    "   'oob_score':[True, False], 'min_samples_split':[2, 4, 6, 8], 'min_samples_leaf':[1, 2, 4, 6, 8]},\n",
    "\n",
    "  {'n_estimators': [5, 10, 15, 20], 'criterion': ['gini', 'entropy'], \\\n",
    "   'random_state':[0], 'class_weight':['balanced', None], 'bootstrap':[False], \\\n",
    "   'min_samples_split':[2, 4, 6, 8], 'min_samples_leaf':[1, 2, 4, 6, 8]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameter_candidates, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the RF\n",
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced', criterion='entropy', n_estimators=50)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we list the feature importance, we'll see if the classifier is working\n",
    "y_pred = clf.predict(X)\n",
    "precision, recall, _ = precision_recall_curve(y_pred, y)\n",
    "print 'precision %.2f' % precision[1]\n",
    "print 'recall %.2f' % recall[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both precision and recall are next to 1.\n",
    "# this is excellent, now we'll list the five most important features\n",
    "#importance = {item[0]:float(item[1]) for item in zip(df.columns[1:-1], clf.feature_importances_)}\n",
    "importance = {item[0]:float(item[1]) for item in zip(df.columns[1:-1], clf.best_estimator_.feature_importances_)}\n",
    "feat_imp = []\n",
    "for w in sorted(importance.iteritems(), key=lambda (k,v):(v,k), reverse=True):\n",
    "    feat_imp.append(np.array(w))\n",
    "feat_imp = np.array(feat_imp)\n",
    "print feat_imp[:5]\n",
    "\n",
    "sum([ float(feat[1]) for feat in feat_imp[:3]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Since the Amount is posively-skewed, a log transformation should do it fine\n",
    "X.Amount += 1\n",
    "X.Amount = FunctionTransformer(np.log).fit_transform(X.Amount.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Checking the Amount distribution\n",
    "sns.distplot(X.Amount)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# separating the legits from the fraudulents\n",
    "legit, fraud = X[X.Class==0], X[X.Class==1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# removing outliers from legit sample\n",
    "for idx, feat in enumerate(legit.columns):\n",
    "    q75, q25 = np.percentile(legit[feat], [75 ,25])\n",
    "    iqr_ = iqr(legit[feat])*1.5\n",
    "    \n",
    "    greater = np.array(legit[feat] < q25 - iqr_, dtype=bool)\n",
    "    legit.loc[greater, feat] = np.nan\n",
    "    \n",
    "    lower   = np.array(legit[feat] > q75 + iqr_, dtype=bool)\n",
    "    legit.loc[lower, feat] = np.nan"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print len(legit)\n",
    "legit.head()\n",
    "\n",
    "# dropping samples with any na\n",
    "X = pd.DataFrame.dropna(legit, how='any')\n",
    "print len(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# now, I'll merge with the fraudulent ones\n",
    "X = pd.concat([X, fraud], axis=0)\n",
    "print len(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we removed the outliers, we can run the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separating the predictors and the labels\n",
    "X, y = X.iloc[:,:-1], X.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xfeat, yfeat, zfeat = feat_imp[0][0], feat_imp[1][0], feat_imp[2][0]\n",
    "\n",
    "ax = plt.subplot(131)\n",
    "X[y==0].plot.scatter(x=xfeat, y=yfeat, ax=ax, alpha=.5)\n",
    "X[y==1].plot.scatter(x=xfeat, y=yfeat, ax=ax, alpha=.5, c='r')\n",
    "\n",
    "ax = plt.subplot(132)\n",
    "X[y==0].plot.scatter(x=xfeat, y=zfeat, ax=ax, alpha=.5)\n",
    "X[y==1].plot.scatter(x=xfeat, y=zfeat, ax=ax, alpha=.5, c='r')\n",
    "\n",
    "ax = plt.subplot(133)\n",
    "X[y==0].plot.scatter(x=yfeat, y=zfeat, ax=ax, alpha=.5)\n",
    "X[y==1].plot.scatter(x=yfeat, y=zfeat, ax=ax, alpha=.5, c='r')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit, fraud = df[df.Class==0], df[df.Class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(legit)), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = legit.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(fraud[xfeat], fraud[yfeat], fraud[zfeat], c='r', s=5, label='fraud')\n",
    "ax.scatter(legit[xfeat], legit[yfeat], legit[zfeat], c='b', s=5, label='legit')\n",
    "\n",
    "ax.set_xlabel(xfeat)\n",
    "ax.set_ylabel(yfeat)\n",
    "ax.set_zlabel(zfeat)\n",
    "\n",
    "plt.title('Scatterplot between %s x %s x %s'%(xfeat, yfeat, zfeat))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = df.iloc[:,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new[['V11', 'V13', 'V15', 'Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new, y_new = X_new.iloc[:,:-1], X_new.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(ratio={0:492*10, 1:492})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "for i in range(50):\n",
    "    X_resampled, y_resampled = rus.fit_sample(X_new, y_new)\n",
    "    clf.partial_fit(X_resampled, y_resampled, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_new)\n",
    "print y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_pred, y_new)\n",
    "print 'precision %.2f' % precision[1]\n",
    "print 'recall %.2f' % recall[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(131)\n",
    "df.boxplot('V11', 'Class', ax=ax)\n",
    "\n",
    "ax = plt.subplot(132)\n",
    "df.boxplot('V13', 'Class', ax=ax)\n",
    "\n",
    "ax = plt.subplot(133)\n",
    "df.boxplot('V15', 'Class', ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the legits from the fraudulents\n",
    "isFraud = np.array(y_new==1, dtype=bool)\n",
    "legit, fraud = X_new[~isFraud], X_new[isFraud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers from legit sample\n",
    "for idx, feat in enumerate(legit.columns):\n",
    "    q75, q25 = np.percentile(legit[feat], [75 ,25])\n",
    "    iqr_ = iqr(legit[feat])*1.5\n",
    "    \n",
    "    greater = np.array(legit[feat] < q25 - iqr_, dtype=bool)\n",
    "    legit.loc[greater, feat] = np.nan\n",
    "    \n",
    "    lower   = np.array(legit[feat] > q75 + iqr_, dtype=bool)\n",
    "    legit.loc[lower, feat] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(legit)\n",
    "legit.head()\n",
    "\n",
    "# dropping samples with any na\n",
    "X_new = pd.DataFrame.dropna(legit, how='any')\n",
    "print len(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, I'll merge with the fraudulent ones\n",
    "X_new = pd.concat([X_new, fraud], axis=0)\n",
    "print len(X_new)\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.concat([X_new, y_new], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(131)\n",
    "X_new.boxplot('V11', 'Class', ax=ax)\n",
    "\n",
    "ax = plt.subplot(132)\n",
    "X_new.boxplot('V13', 'Class', ax=ax)\n",
    "\n",
    "ax = plt.subplot(133)\n",
    "X_new.boxplot('V15', 'Class', ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
